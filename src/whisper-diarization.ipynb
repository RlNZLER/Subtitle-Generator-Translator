{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RlNZLER/Subtitle-Generator-Translator/blob/main/src/whisper-diarization.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "# Step 1:\n",
        "# Execute the following task and upload an audio file, or files, to the content directory while you wait for the task to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ddeepak95/whisper-diarization.git\n",
        "!pip install cython\n",
        "!pip install -c whisper-diarization/constraints.txt -r whisper-diarization/requirements.txt\n",
        "!pip install pydub ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvUJvJyHGeL4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "\n",
        "def split_audio(audio_path, output_dir=\"/content/source_files\", max_length_minutes=45):\n",
        "    \"\"\"\n",
        "    Splits an audio file into chunks of a specified maximum length and saves to output directory.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): The path to the audio file.\n",
        "        output_dir (str): Directory where output files will be saved.\n",
        "        max_length_minutes (int): The maximum length of each chunk in minutes.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        duration_minutes = len(audio) / (1000 * 60)\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        if duration_minutes > max_length_minutes:\n",
        "            print(f\"Audio file {audio_path} is longer than {max_length_minutes} minutes. Splitting...\")\n",
        "            chunk_length_ms = max_length_minutes * 60 * 1000\n",
        "            num_chunks = math.ceil(duration_minutes / max_length_minutes)\n",
        "\n",
        "            for i in range(num_chunks):\n",
        "                start_time = i * chunk_length_ms\n",
        "                end_time = (i + 1) * chunk_length_ms\n",
        "                chunk = audio[start_time:end_time]\n",
        "\n",
        "                base = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "                output_path = os.path.join(output_dir, f\"{base}_part{i+1}.mp3\")\n",
        "                chunk.export(output_path, format=\"mp3\")\n",
        "\n",
        "                print(f\"Exported chunk {i+1} to {output_path}\")\n",
        "        else:\n",
        "            # Move file to output_dir if it's short enough\n",
        "            destination_path = os.path.join(output_dir, os.path.basename(audio_path))\n",
        "            shutil.move(audio_path, destination_path)\n",
        "            print(f\"Moved {audio_path} to {destination_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "\n",
        "# Iterate through files in /content and split if necessary\n",
        "content_dir = \"/content\"\n",
        "output_dir = \"/content/source_files\"\n",
        "for filename in os.listdir(content_dir):\n",
        "    file_path = os.path.join(content_dir, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        split_audio(file_path, output_dir=output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step23"
      },
      "source": [
        "# Step 2:\n",
        "# ^ !!! WAIT FOR ABOVE TASK TO COMPLETE !!! ^\n",
        "# ^ !!! BEFORE RESTARTING RUNTIME !!! ^\n",
        "(you can also skip restarting the runtime when asked)\n",
        "\n",
        "# Step 3:\n",
        "# Once the above task has completed and all audio files have successfully been uploaded to the content directory, execute the following task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate"
      },
      "outputs": [],
      "source": [
        "import glob, os\n",
        "audioFiles = glob.glob(\"/content/source_files/*.*\")\n",
        "os.chdir(\"/content/whisper-diarization\")\n",
        "for i in range(len(audioFiles)):\n",
        "  for audioFile in glob.glob(audioFiles[i]):\n",
        "    baseFile = os.path.splitext(audioFile)[0]\n",
        "    !python diarize_parallel.py --whisper-model large-v3 -a \"$audioFile\" --language \"en\" --no-stem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "# Step 4:\n",
        "# Download the srt and txt files from the content directory."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
